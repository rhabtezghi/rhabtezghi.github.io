{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-81b83777-e77c-4bc0-ac14-fd72419a44e0",
    "deepnote_cell_height": 758.671875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 26,
    "execution_start": 1653742218732,
    "source_hash": "549f8513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all packages\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "print(\"Successfully imported all packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-6212e93b-5c50-4515-8baf-e4a011deda14",
    "deepnote_cell_height": 69.6875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "83e962e4fe9d4c96862dcbae4eb5ce99",
    "deepnote_cell_height": 134.6875,
    "deepnote_cell_type": "code",
    "deepnote_table_invalid": false,
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 1,
     "pageSize": 10,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 263,
    "execution_start": 1653742223818,
    "source_hash": "9fd981b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/socialmedia-disaster-tweets-DFE 3.csv', error_bad_lines=False)\n",
    "data = data.drop(columns=[\"_unit_id\", \"_golden\", \"_unit_state\", \"_trusted_judgments\",\"choose_one:confidence\", \"choose_one_gold\", \"_last_judgment_at\"])\n",
    "data[\"target\"] = data.apply(lambda row: 1 if row[\"choose_one\"]== \"Relevant\" else 0 ,axis =1)\n",
    "full_dataset = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5565578a6293461d993ad9020784d442",
    "deepnote_cell_height": 69.6875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8f741f360e814e758a118e465d4585bd",
    "deepnote_cell_height": 249.53125,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Explore dataset dimensionality:\n",
    "1. Any missing values?\n",
    "2. How many datapoints of each class?\n",
    "3. Average length of tweets in each class + box plot\n",
    "4. How many words in total?\n",
    "5. How many unique words?\n",
    "6. How many unique words after stop word removal?\n",
    "6. How many unique words after lemmitization?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "157a2a191c074faa82300aa48c2c0c5e",
    "deepnote_cell_height": 269.578125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     155.03125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1653742226949,
    "source_hash": "d3307a90",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_one    10876\n",
       "keyword       10789\n",
       "location       7238\n",
       "text          10876\n",
       "tweetid       10876\n",
       "userid        10789\n",
       "target        10876\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1 - we conclude that Location and Keyword have significant amounts of NAs \n",
    "full_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1b17bb6d4edb4359ac8228712c4e46e5",
    "deepnote_cell_height": 204.0625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1653742229455,
    "source_hash": "9f6f2dec",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  target    0\n",
      "dtype: int64\n",
      "Text:  text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NAs in classes of relevance - non found \n",
    "print('Target: ', full_dataset[['target']].isna().sum())\n",
    "print('Text: ', full_dataset[['text']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "39de274c99d343eda31d4382776ff22c",
    "deepnote_cell_height": 368.328125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1653742230609,
    "source_hash": "eb521462",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "target      \n",
      "0       6203\n",
      "1       4673\n",
      "zeroes %:  57.03383596910629\n",
      "ones %:  42.96616403089371\n"
     ]
    }
   ],
   "source": [
    "# Task 2 - numer of instances of each class\n",
    "x = pd.DataFrame(full_dataset[['target']].value_counts())\n",
    "print(x)\n",
    "\n",
    "# Calculate percentages\n",
    "zero = x.iat[0,0] / x[0].sum()\n",
    "ones = x.iat[1,0] / x[0].sum()\n",
    "\n",
    "print('zeroes %: ', zero *100)\n",
    "print('ones %: ', ones*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "aeb44178f95c4195a6678202f53d5a11",
    "deepnote_cell_height": 204.0625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 45,
    "execution_start": 1653742232710,
    "source_hash": "4491efeb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    14.709012\n",
      "1    15.205007\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Task 3.1 - average length of tweet\n",
    "full_dataset['word_count'] = full_dataset['text'].str.split().str.len() # Count words of tweet and add to new column in df\n",
    "print(full_dataset.groupby('target')['word_count'].mean()) # Group by target and average over the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e01b7f67ab47406d9a4da02e2f26a4d0",
    "deepnote_cell_height": 278.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 30,
    "execution_start": 1653742234451,
    "source_hash": "3cec56b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.2 - BoxPlot of the classes\n",
    "\n",
    "# Extract values\n",
    "trg = full_dataset.groupby('target')\n",
    "wordcount_0 = trg.get_group(0)\n",
    "wordcount_1 = trg.get_group(1)\n",
    "\n",
    "zeroes_wordcount = wordcount_0[['word_count']]\n",
    "ones_wordcount = wordcount_1[['word_count']]\n",
    "\n",
    "zeroes_wordcount = zeroes_wordcount[['word_count']].to_numpy().flatten()\n",
    "ones_wordcount = ones_wordcount[['word_count']].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f3569708b25148fcba87540b975fbbb1",
    "deepnote_cell_height": 470.53125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     265.984375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 550,
    "execution_start": 1653742236015,
    "source_hash": "3f38a3a5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 379
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot\n",
    "bp_data = [zeroes_wordcount, ones_wordcount]\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Number of words in tweets per class')\n",
    "ax.boxplot(bp_data, patch_artist = True, vert = False, labels = ('Zero', 'One'), widths=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ae882ea61a0c4ea79eb6b0bb8a820a48",
    "deepnote_cell_height": 273.8125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1653745087968,
    "source_hash": "288ebb3a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# Min max length tweet\n",
    "\n",
    "min_z = min(full_dataset['word_count'])\n",
    "min_o = min(full_dataset['word_count'])\n",
    "print(min([min_z, min_o]))\n",
    "\n",
    "max_z = max(full_dataset['word_count'])\n",
    "max_o = max(full_dataset['word_count'])\n",
    "print(max([max_z, max_o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a3c25489c3394d68ab8cea10372608fb",
    "deepnote_cell_height": 406.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1653742239417,
    "source_hash": "a61f101e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dataset:  162293\n",
      "Number of words per class:  target\n",
      "0    91240\n",
      "1    71053\n",
      "Name: word_count, dtype: int64\n",
      "Percentages\n",
      "Zeroes:  56.219307055757184\n",
      "Ones:  43.78069294424282\n"
     ]
    }
   ],
   "source": [
    "# Task 4 - total amount of words\n",
    "print('Number of words in dataset: ', full_dataset['word_count'].sum())\n",
    "# Words per class\n",
    "print('Number of words per class: ', full_dataset.groupby('target')['word_count'].sum())\n",
    "\n",
    "words_in_class = pd.DataFrame(full_dataset.groupby('target')['word_count'].sum())\n",
    "\n",
    "print('Percentages') # Calculate percentages of words beloning to each class\n",
    "print('Zeroes: ', (words_in_class.iat[0,0] / (words_in_class.iat[0,0] + words_in_class.iat[1,0]))*100)\n",
    "print('Ones: ', (words_in_class.iat[1,0] / (words_in_class.iat[0,0] + words_in_class.iat[1,0]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4625b56e74d046dc9afae996905839f5",
    "deepnote_cell_height": 344.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69,
    "execution_start": 1653742292426,
    "source_hash": "4a7683c7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  36613\n"
     ]
    }
   ],
   "source": [
    "# Task 5 - n.o. unique words\n",
    "all_words_list = data['text'].tolist()\n",
    "\n",
    "#print(all_words_list)\n",
    "\n",
    "# Create list with all words in the text column\n",
    "all_words = []\n",
    "for ls in all_words_list:\n",
    "    for word in ls.split():\n",
    "        all_words.append(word.lower())\n",
    "\n",
    "# Remove duplicates\n",
    "all_words_set = set(all_words)\n",
    "print('Number of unique words: ', len(all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "df27164be4154dee803f89fedfc75a36",
    "deepnote_cell_height": 368.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 475,
    "execution_start": 1653745385994,
    "owner_user_id": "10497c3e-12c3-4d9c-ba80-069d2fe2d915",
    "source_hash": "c3687900",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Most frequent word and special char\n",
    "all_words_sort = sorted(all_chars)\n",
    "\n",
    "count_words = {}\n",
    "iterator = 0\n",
    "count = 1\n",
    "for iterator in range(len(all_words_sort) - 1):\n",
    "    if all_words_sort[iterator] == all_words_sort[iterator + 1]:\n",
    "        count += 1\n",
    "        count_words[all_words_sort[iterator]] = count\n",
    "        #count_words.append((all_words_sort[iterator], count))\n",
    "    else:\n",
    "        count_words[all_words_sort[iterator]] = count\n",
    "        #count_words.append((all_words_sort[iterator], count))\n",
    "        count = 0\n",
    "\n",
    "dict_count = {k: v for k, v in sorted(count_words.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "30de34fa50144a5aa07b4e17680a4ce4",
    "deepnote_cell_height": 295.015625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.109375
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1653745388680,
    "source_hash": "87807ace",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('>', 0), ('\\x81', 0), ('¬', 0), ('´', 0), ('«', 1), ('ã', 1), ('ä', 1), ('ç', 1), ('ü', 1), ('`', 2), ('¤', 2), ('á', 2), ('¡', 3), ('à', 3), ('ñ', 3), ('â', 4), (',', 5), ('{', 5), ('¼', 5), ('è', 5), ('\\\\', 6), ('}', 6), ('¨', 7), ('^', 8), ('£', 8), ('©', 13), ('¢', 18), ('ì', 41), ('~', 46), ('ó', 54), ('\\x9d', 60), ('÷', 61), ('%', 62), ('=', 65), ('$', 66), ('ò', 75), ('ê', 92), ('ï', 94), ('+', 107), ('å', 137), (']', 188), ('[', 190), ('|', 214), ('ª', 271), ('*', 273), ('(', 504), (')', 545), ('&', 650), (';', 835), ('û', 1162), ('‰', 1165), ('_', 1253), ('8', 1605), ('6', 1664), ('!', 1667), ('9', 1714), ('7', 1786), ('4', 1907), ('3', 2158), ('5', 2163), ('-', 2448), ('2', 2491), ('q', 2835), ('1', 3198), ('0', 3504), ('z', 3555), ('x', 3945), ('@', 4038), ('?', 4457), (\"'\", 4470), ('j', 4608), ('#', 4945), (':', 9908), ('v', 10463), ('k', 11447), ('b', 16614), ('.', 16838), ('w', 16840), ('y', 17664), ('f', 17999), ('g', 19559), ('/', 20919), ('m', 24320), ('p', 24648), ('u', 24987), ('d', 31243), ('c', 32188), ('l', 36638), ('h', 38682), ('r', 50254), ('s', 52235), ('n', 52638), ('i', 58209), ('o', 65138), ('a', 66772), ('t', 80909), ('e', 84657)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "n_place = len(dict_count)\n",
    "n_items = take(n_place, dict_count.items())\n",
    "\n",
    "print(n_items[-100:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "158c0619709a40788e9252ae76ae2bd7",
    "deepnote_cell_height": 272.703125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 126,
    "execution_start": 1653742333880,
    "source_hash": "31eec25f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words after tokenization  36613\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - How many unique words after tokenization removal?\n",
    "tok_full = data['tweet_tokens']\n",
    "tok_all_words = []\n",
    "\n",
    "for ls in tok_full:\n",
    "    for word in ls:\n",
    "        tok_all_words.append(word.lower())\n",
    "tok_all_words_set = set(tok_all_words)\n",
    "\n",
    "print('Number of unique words after tokenization ', len(tok_all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6ba004174316486099a41ca511b0d376",
    "deepnote_cell_height": 272.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 87,
    "execution_start": 1653742335222,
    "source_hash": "e5781020",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words after removing stop words:  36595\n"
     ]
    }
   ],
   "source": [
    "# Task 6 - How many unique words after stop word removal?\n",
    "stop_full = data['cleaned_tweets']\n",
    "stop_all_words = []\n",
    "\n",
    "for ls in stop_full:\n",
    "    for word in ls:\n",
    "        stop_all_words.append(word.lower())\n",
    "stop_all_words_set = set(stop_all_words)\n",
    "\n",
    "print('Number of unique words after removing stop words: ', len(stop_all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8f4deb9a95ec4b4f8ba5427a8e4420c2",
    "deepnote_cell_height": 290.671875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 112,
    "execution_start": 1653742359417,
    "source_hash": "c8566424",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words after lemmatization:  35995\n"
     ]
    }
   ],
   "source": [
    "# Task 7 - How many unique words after lemmitization?\n",
    "\n",
    "lemmatized_full = data['lemmatized_tweets']\n",
    "lemmatized_all_words = []\n",
    "\n",
    "for ls in lemmatized_full:\n",
    "    for word in ls:\n",
    "        lemmatized_all_words.append(word.lower())\n",
    "lemmatized_all_words_set = set(lemmatized_all_words)\n",
    "\n",
    "print('Number of unique words after lemmatization: ', len(lemmatized_all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2cadf7dd631a478a94b591157a4f1daa",
    "deepnote_cell_height": 296.15625,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 207,
    "execution_start": 1653742410094,
    "source_hash": "30ef16fb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in dataset:  97\n",
      "['!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x81', '\\x9d', '¡', '¢', '£', '¤', '¨', '©', 'ª', '«', '¬', '´', '¼', 'à', 'á', 'â', 'ã', 'ä', 'å', 'ç', 'è', 'ê', 'ì', 'ï', 'ñ', 'ò', 'ó', '÷', 'û', 'ü', '‰']\n"
     ]
    }
   ],
   "source": [
    "# Unique characters in data\n",
    "all_chars = []\n",
    "for word in all_words:\n",
    "    for char in word:\n",
    "        all_chars.append(char)\n",
    "\n",
    "all_chars_set = set(all_chars)\n",
    "sort_char = sorted(all_chars_set)\n",
    "print('Number of unique characters in dataset: ', len(all_chars_set))\n",
    "print(sort_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-b27b8f83-363d-4c6c-8c8e-f5054626de8f",
    "deepnote_cell_height": 69.6875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-bac7f5ad-a311-45b7-ac8d-a5184f613164",
    "deepnote_cell_height": 61,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-fa4dd0a4-14ca-4799-9135-5b382b680bb4",
    "deepnote_cell_height": 116.6875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 388,
    "execution_start": 1653742302153,
    "source_hash": "9d3a0350"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "data[\"tweet_tokens\"] = data.apply(lambda row: row[\"text\"].split(), axis = 1)\n",
    "data[\"tweet_tokens_joined\"] = data.apply(lambda row: \" \".join(row[\"tweet_tokens\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-9545b97d-f686-4915-9c1b-c73f34c28089",
    "deepnote_cell_height": 61,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-167d7ffb-62e1-41bb-9943-726f1dba1e8f",
    "deepnote_cell_height": 689.3125,
    "deepnote_cell_type": "code",
    "deepnote_table_loading": false,
    "deepnote_table_state": {
     "filters": [],
     "pageIndex": 0,
     "pageSize": 50,
     "sortBy": []
    },
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 489,
    "execution_start": 1653742304390,
    "source_hash": "4dfb7349"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 12,
       "columns": [
        {
         "dtype": "object",
         "name": "choose_one",
         "stats": {
          "categories": [
           {
            "count": 10,
            "name": "Relevant"
           }
          ],
          "nan_count": 0,
          "unique_count": 1
         }
        },
        {
         "dtype": "object",
         "name": "keyword",
         "stats": {
          "categories": [
           {
            "count": 10,
            "name": "Missing"
           }
          ],
          "nan_count": 10,
          "unique_count": 0
         }
        },
        {
         "dtype": "object",
         "name": "location",
         "stats": {
          "categories": [
           {
            "count": 10,
            "name": "Missing"
           }
          ],
          "nan_count": 10,
          "unique_count": 0
         }
        },
        {
         "dtype": "object",
         "name": "text",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened a terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all"
           },
           {
            "count": 8,
            "name": "8 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "float64",
         "name": "tweetid",
         "stats": {
          "histogram": [
           {
            "bin_end": 3,
            "bin_start": 1,
            "count": 1
           },
           {
            "bin_end": 5,
            "bin_start": 3,
            "count": 0
           },
           {
            "bin_end": 7,
            "bin_start": 5,
            "count": 0
           },
           {
            "bin_end": 9,
            "bin_start": 7,
            "count": 0
           },
           {
            "bin_end": 11,
            "bin_start": 9,
            "count": 0
           },
           {
            "bin_end": 13,
            "bin_start": 11,
            "count": 0
           },
           {
            "bin_end": 15,
            "bin_start": 13,
            "count": 2
           },
           {
            "bin_end": 17,
            "bin_start": 15,
            "count": 2
           },
           {
            "bin_end": 19,
            "bin_start": 17,
            "count": 2
           },
           {
            "bin_end": 21,
            "bin_start": 19,
            "count": 3
           }
          ],
          "max": "21.0",
          "min": "1.0",
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "float64",
         "name": "userid",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.1,
            "bin_start": 0,
            "count": 0
           },
           {
            "bin_end": 0.2,
            "bin_start": 0.1,
            "count": 0
           },
           {
            "bin_end": 0.30000000000000004,
            "bin_start": 0.2,
            "count": 0
           },
           {
            "bin_end": 0.4,
            "bin_start": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_end": 0.5,
            "bin_start": 0.4,
            "count": 0
           },
           {
            "bin_end": 0.6000000000000001,
            "bin_start": 0.5,
            "count": 0
           },
           {
            "bin_end": 0.7000000000000001,
            "bin_start": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_end": 0.8,
            "bin_start": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_end": 0.9,
            "bin_start": 0.8,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9,
            "count": 0
           }
          ],
          "max": null,
          "min": null,
          "nan_count": 10,
          "unique_count": 0
         }
        },
        {
         "dtype": "int64",
         "name": "target",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6,
            "bin_start": 0.5,
            "count": 0
           },
           {
            "bin_end": 0.7,
            "bin_start": 0.6,
            "count": 0
           },
           {
            "bin_end": 0.8,
            "bin_start": 0.7,
            "count": 0
           },
           {
            "bin_end": 0.9,
            "bin_start": 0.8,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9,
            "count": 0
           },
           {
            "bin_end": 1.1,
            "bin_start": 1,
            "count": 10
           },
           {
            "bin_end": 1.2000000000000002,
            "bin_start": 1.1,
            "count": 0
           },
           {
            "bin_end": 1.3,
            "bin_start": 1.2000000000000002,
            "count": 0
           },
           {
            "bin_end": 1.4,
            "bin_start": 1.3,
            "count": 0
           },
           {
            "bin_end": 1.5,
            "bin_start": 1.4,
            "count": 0
           }
          ],
          "max": "1",
          "min": "1",
          "nan_count": 0,
          "unique_count": 1
         }
        },
        {
         "dtype": "int64",
         "name": "word_count",
         "stats": {
          "histogram": [
           {
            "bin_end": 5.8,
            "bin_start": 4,
            "count": 1
           },
           {
            "bin_end": 7.6,
            "bin_start": 5.8,
            "count": 2
           },
           {
            "bin_end": 9.4,
            "bin_start": 7.6,
            "count": 2
           },
           {
            "bin_end": 11.2,
            "bin_start": 9.4,
            "count": 0
           },
           {
            "bin_end": 13,
            "bin_start": 11.2,
            "count": 0
           },
           {
            "bin_end": 14.8,
            "bin_start": 13,
            "count": 1
           },
           {
            "bin_end": 16.6,
            "bin_start": 14.8,
            "count": 1
           },
           {
            "bin_end": 18.4,
            "bin_start": 16.6,
            "count": 1
           },
           {
            "bin_end": 20.2,
            "bin_start": 18.4,
            "count": 1
           },
           {
            "bin_end": 22,
            "bin_start": 20.2,
            "count": 1
           }
          ],
          "max": "22",
          "min": "4",
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "object",
         "name": "tweet_tokens",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "['Just', 'happened', 'a', 'terrible', 'car', 'crash']"
           },
           {
            "count": 1,
            "name": "['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']"
           },
           {
            "count": 8,
            "name": "8 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "object",
         "name": "tweet_tokens_joined",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened a terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all"
           },
           {
            "count": 8,
            "name": "8 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "object",
         "name": "cleaned_tweets",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "['Just', 'happened', 'terrible', 'car', 'crash']"
           },
           {
            "count": 1,
            "name": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us']"
           },
           {
            "count": 8,
            "name": "8 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "object",
         "name": "cleaned_tweets_joined",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds Reason #earthquake May ALLAH Forgive us"
           },
           {
            "count": 8,
            "name": "8 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 10
         }
        },
        {
         "dtype": "int64",
         "name": "_deepnote_index_column"
        }
       ],
       "row_count": 10,
       "rows": [
        {
         "_deepnote_index_column": 0,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Just', 'happened', 'terrible', 'car', 'crash']",
         "cleaned_tweets_joined": "Just happened terrible car crash",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Just happened a terrible car crash",
         "tweet_tokens": "['Just', 'happened', 'a', 'terrible', 'car', 'crash']",
         "tweet_tokens_joined": "Just happened a terrible car crash",
         "tweetid": 1,
         "userid": "nan",
         "word_count": 6
        },
        {
         "_deepnote_index_column": 1,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us']",
         "cleaned_tweets_joined": "Our Deeds Reason #earthquake May ALLAH Forgive us",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all",
         "tweet_tokens": "['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']",
         "tweet_tokens_joined": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all",
         "tweetid": 13,
         "userid": "nan",
         "word_count": 13
        },
        {
         "_deepnote_index_column": 2,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Heard', '#earthquake', 'different', 'cities,', 'stay', 'safe', 'everyone.']",
         "cleaned_tweets_joined": "Heard #earthquake different cities, stay safe everyone.",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Heard about #earthquake is different cities, stay safe everyone.",
         "tweet_tokens": "['Heard', 'about', '#earthquake', 'is', 'different', 'cities,', 'stay', 'safe', 'everyone.']",
         "tweet_tokens_joined": "Heard about #earthquake is different cities, stay safe everyone.",
         "tweetid": 14,
         "userid": "nan",
         "word_count": 9
        },
        {
         "_deepnote_index_column": 3,
         "choose_one": "Relevant",
         "cleaned_tweets": "['forest', 'fire', 'spot', 'pond,', 'geese', 'fleeing', 'across', 'street,', 'I', 'cannot', 'save']",
         "cleaned_tweets_joined": "forest fire spot pond, geese fleeing across street, I cannot save",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all",
         "tweet_tokens": "['there', 'is', 'a', 'forest', 'fire', 'at', 'spot', 'pond,', 'geese', 'are', 'fleeing', 'across', 'the', 'street,', 'I', 'cannot', 'save', 'them', 'all']",
         "tweet_tokens_joined": "there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all",
         "tweetid": 15,
         "userid": "nan",
         "word_count": 19
        },
        {
         "_deepnote_index_column": 4,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask.', 'Canada']",
         "cleaned_tweets_joined": "Forest fire near La Ronge Sask. Canada",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Forest fire near La Ronge Sask. Canada",
         "tweet_tokens": "['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask.', 'Canada']",
         "tweet_tokens_joined": "Forest fire near La Ronge Sask. Canada",
         "tweetid": 16,
         "userid": "nan",
         "word_count": 7
        },
        {
         "_deepnote_index_column": 5,
         "choose_one": "Relevant",
         "cleaned_tweets": "['All', 'residents', 'asked', \"'shelter\", \"place'\", 'notified', 'officers.', 'No', 'evacuation', 'shelter', 'place', 'orders', 'expected']",
         "cleaned_tweets_joined": "All residents asked 'shelter place' notified officers. No evacuation shelter place orders expected",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected",
         "tweet_tokens": "['All', 'residents', 'asked', 'to', \"'shelter\", 'in', \"place'\", 'are', 'being', 'notified', 'by', 'officers.', 'No', 'other', 'evacuation', 'or', 'shelter', 'in', 'place', 'orders', 'are', 'expected']",
         "tweet_tokens_joined": "All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected",
         "tweetid": 17,
         "userid": "nan",
         "word_count": 22
        },
        {
         "_deepnote_index_column": 6,
         "choose_one": "Relevant",
         "cleaned_tweets": "['13,000', 'people', 'receive', '#wildfires', 'evacuation', 'orders', 'California']",
         "cleaned_tweets_joined": "13,000 people receive #wildfires evacuation orders California",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "13,000 people receive #wildfires evacuation orders in California ",
         "tweet_tokens": "['13,000', 'people', 'receive', '#wildfires', 'evacuation', 'orders', 'in', 'California']",
         "tweet_tokens_joined": "13,000 people receive #wildfires evacuation orders in California",
         "tweetid": 18,
         "userid": "nan",
         "word_count": 8
        },
        {
         "_deepnote_index_column": 7,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Just', 'got', 'sent', 'photo', 'Ruby', '#Alaska', 'smoke', '#wildfires', 'pours', 'school']",
         "cleaned_tweets_joined": "Just got sent photo Ruby #Alaska smoke #wildfires pours school",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school ",
         "tweet_tokens": "['Just', 'got', 'sent', 'this', 'photo', 'from', 'Ruby', '#Alaska', 'as', 'smoke', 'from', '#wildfires', 'pours', 'into', 'a', 'school']",
         "tweet_tokens_joined": "Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school",
         "tweetid": 19,
         "userid": "nan",
         "word_count": 16
        },
        {
         "_deepnote_index_column": 8,
         "choose_one": "Relevant",
         "cleaned_tweets": "['#RockyFire', 'Update', '=>', 'California', 'Hwy.', '20', 'closed', 'directions', 'due', 'Lake', 'County', 'fire', '-', '#CAfire', '#wildfires']",
         "cleaned_tweets_joined": "#RockyFire Update => California Hwy. 20 closed directions due Lake County fire - #CAfire #wildfires",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires",
         "tweet_tokens": "['#RockyFire', 'Update', '=>', 'California', 'Hwy.', '20', 'closed', 'in', 'both', 'directions', 'due', 'to', 'Lake', 'County', 'fire', '-', '#CAfire', '#wildfires']",
         "tweet_tokens_joined": "#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires",
         "tweetid": 20,
         "userid": "nan",
         "word_count": 18
        },
        {
         "_deepnote_index_column": 9,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Apocalypse', 'lighting.', '#Spokane', '#wildfires']",
         "cleaned_tweets_joined": "Apocalypse lighting. #Spokane #wildfires",
         "keyword": "nan",
         "location": "nan",
         "target": 1,
         "text": "Apocalypse lighting. #Spokane #wildfires",
         "tweet_tokens": "['Apocalypse', 'lighting.', '#Spokane', '#wildfires']",
         "tweet_tokens_joined": "Apocalypse lighting. #Spokane #wildfires",
         "tweetid": 21,
         "userid": "nan",
         "word_count": 4
        }
       ]
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choose_one</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_tokens_joined</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>cleaned_tweets_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[Just, happened, a, terrible, car, crash]</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[Just, happened, terrible, car, crash]</td>\n",
       "      <td>Just happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #eart...</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[Our, Deeds, Reason, #earthquake, May, ALLAH, ...</td>\n",
       "      <td>Our Deeds Reason #earthquake May ALLAH Forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[Heard, about, #earthquake, is, different, cit...</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[Heard, #earthquake, different, cities,, stay,...</td>\n",
       "      <td>Heard #earthquake different cities, stay safe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>[there, is, a, forest, fire, at, spot, pond,, ...</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[forest, fire, spot, pond,, geese, fleeing, ac...</td>\n",
       "      <td>forest fire spot pond, geese fleeing across st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask., Canada]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask., Canada]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[All, residents, asked, 'shelter, place', noti...</td>\n",
       "      <td>All residents asked 'shelter place' notified o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[13,000, people, receive, #wildfires, evacuati...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[13,000, people, receive, #wildfires, evacuati...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #Al...</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>[Just, got, sent, photo, Ruby, #Alaska, smoke,...</td>\n",
       "      <td>Just got sent photo Ruby #Alaska smoke #wildfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>[#RockyFire, Update, =&gt;, California, Hwy., 20,...</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>[#RockyFire, Update, =&gt;, California, Hwy., 20,...</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[Apocalypse, lighting., #Spokane, #wildfires]</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[Apocalypse, lighting., #Spokane, #wildfires]</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choose_one keyword location  \\\n",
       "0   Relevant     NaN      NaN   \n",
       "1   Relevant     NaN      NaN   \n",
       "2   Relevant     NaN      NaN   \n",
       "3   Relevant     NaN      NaN   \n",
       "4   Relevant     NaN      NaN   \n",
       "5   Relevant     NaN      NaN   \n",
       "6   Relevant     NaN      NaN   \n",
       "7   Relevant     NaN      NaN   \n",
       "8   Relevant     NaN      NaN   \n",
       "9   Relevant     NaN      NaN   \n",
       "\n",
       "                                                text  tweetid  userid  target  \\\n",
       "0                 Just happened a terrible car crash      1.0     NaN       1   \n",
       "1  Our Deeds are the Reason of this #earthquake M...     13.0     NaN       1   \n",
       "2  Heard about #earthquake is different cities, s...     14.0     NaN       1   \n",
       "3  there is a forest fire at spot pond, geese are...     15.0     NaN       1   \n",
       "4             Forest fire near La Ronge Sask. Canada     16.0     NaN       1   \n",
       "5  All residents asked to 'shelter in place' are ...     17.0     NaN       1   \n",
       "6  13,000 people receive #wildfires evacuation or...     18.0     NaN       1   \n",
       "7  Just got sent this photo from Ruby #Alaska as ...     19.0     NaN       1   \n",
       "8  #RockyFire Update => California Hwy. 20 closed...     20.0     NaN       1   \n",
       "9           Apocalypse lighting. #Spokane #wildfires     21.0     NaN       1   \n",
       "\n",
       "   word_count                                       tweet_tokens  \\\n",
       "0           6          [Just, happened, a, terrible, car, crash]   \n",
       "1          13  [Our, Deeds, are, the, Reason, of, this, #eart...   \n",
       "2           9  [Heard, about, #earthquake, is, different, cit...   \n",
       "3          19  [there, is, a, forest, fire, at, spot, pond,, ...   \n",
       "4           7     [Forest, fire, near, La, Ronge, Sask., Canada]   \n",
       "5          22  [All, residents, asked, to, 'shelter, in, plac...   \n",
       "6           8  [13,000, people, receive, #wildfires, evacuati...   \n",
       "7          16  [Just, got, sent, this, photo, from, Ruby, #Al...   \n",
       "8          18  [#RockyFire, Update, =>, California, Hwy., 20,...   \n",
       "9           4      [Apocalypse, lighting., #Spokane, #wildfires]   \n",
       "\n",
       "                                 tweet_tokens_joined  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Our Deeds are the Reason of this #earthquake M...   \n",
       "2  Heard about #earthquake is different cities, s...   \n",
       "3  there is a forest fire at spot pond, geese are...   \n",
       "4             Forest fire near La Ronge Sask. Canada   \n",
       "5  All residents asked to 'shelter in place' are ...   \n",
       "6  13,000 people receive #wildfires evacuation or...   \n",
       "7  Just got sent this photo from Ruby #Alaska as ...   \n",
       "8  #RockyFire Update => California Hwy. 20 closed...   \n",
       "9           Apocalypse lighting. #Spokane #wildfires   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0             [Just, happened, terrible, car, crash]   \n",
       "1  [Our, Deeds, Reason, #earthquake, May, ALLAH, ...   \n",
       "2  [Heard, #earthquake, different, cities,, stay,...   \n",
       "3  [forest, fire, spot, pond,, geese, fleeing, ac...   \n",
       "4     [Forest, fire, near, La, Ronge, Sask., Canada]   \n",
       "5  [All, residents, asked, 'shelter, place', noti...   \n",
       "6  [13,000, people, receive, #wildfires, evacuati...   \n",
       "7  [Just, got, sent, photo, Ruby, #Alaska, smoke,...   \n",
       "8  [#RockyFire, Update, =>, California, Hwy., 20,...   \n",
       "9      [Apocalypse, lighting., #Spokane, #wildfires]   \n",
       "\n",
       "                               cleaned_tweets_joined  \n",
       "0                   Just happened terrible car crash  \n",
       "1  Our Deeds Reason #earthquake May ALLAH Forgive us  \n",
       "2  Heard #earthquake different cities, stay safe ...  \n",
       "3  forest fire spot pond, geese fleeing across st...  \n",
       "4             Forest fire near La Ronge Sask. Canada  \n",
       "5  All residents asked 'shelter place' notified o...  \n",
       "6  13,000 people receive #wildfires evacuation or...  \n",
       "7  Just got sent photo Ruby #Alaska smoke #wildfi...  \n",
       "8  #RockyFire Update => California Hwy. 20 closed...  \n",
       "9           Apocalypse lighting. #Spokane #wildfires  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "data['cleaned_tweets'] = data.apply(lambda row: [w for w in row[\"tweet_tokens\"] if w not in stopset], axis = 1)\n",
    "data[\"cleaned_tweets_joined\"] = data.apply(lambda row: \" \".join(row[\"cleaned_tweets\"]), axis = 1)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-eeda3e79-3c00-4bf4-9439-abe05d5fd70f",
    "deepnote_cell_height": 61,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-15813b93-5231-4419-b8d1-8888d84a21e1",
    "deepnote_cell_height": 484.359375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4187,
    "execution_start": 1653742316449,
    "source_hash": "3f5f4661"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.deepnote.dataframe.v3+json": {
       "column_count": 14,
       "columns": [
        {
         "dtype": "object",
         "name": "choose_one",
         "stats": {
          "categories": [
           {
            "count": 5,
            "name": "Relevant"
           }
          ],
          "nan_count": 0,
          "unique_count": 1
         }
        },
        {
         "dtype": "object",
         "name": "keyword",
         "stats": {
          "categories": [
           {
            "count": 5,
            "name": "Missing"
           }
          ],
          "nan_count": 5,
          "unique_count": 0
         }
        },
        {
         "dtype": "object",
         "name": "location",
         "stats": {
          "categories": [
           {
            "count": 5,
            "name": "Missing"
           }
          ],
          "nan_count": 5,
          "unique_count": 0
         }
        },
        {
         "dtype": "object",
         "name": "text",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened a terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "tweetid",
         "stats": {
          "histogram": [
           {
            "bin_end": 2.5,
            "bin_start": 1,
            "count": 1
           },
           {
            "bin_end": 4,
            "bin_start": 2.5,
            "count": 0
           },
           {
            "bin_end": 5.5,
            "bin_start": 4,
            "count": 0
           },
           {
            "bin_end": 7,
            "bin_start": 5.5,
            "count": 0
           },
           {
            "bin_end": 8.5,
            "bin_start": 7,
            "count": 0
           },
           {
            "bin_end": 10,
            "bin_start": 8.5,
            "count": 0
           },
           {
            "bin_end": 11.5,
            "bin_start": 10,
            "count": 0
           },
           {
            "bin_end": 13,
            "bin_start": 11.5,
            "count": 0
           },
           {
            "bin_end": 14.5,
            "bin_start": 13,
            "count": 2
           },
           {
            "bin_end": 16,
            "bin_start": 14.5,
            "count": 2
           }
          ],
          "max": "16.0",
          "min": "1.0",
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "float64",
         "name": "userid",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.1,
            "bin_start": 0,
            "count": 0
           },
           {
            "bin_end": 0.2,
            "bin_start": 0.1,
            "count": 0
           },
           {
            "bin_end": 0.30000000000000004,
            "bin_start": 0.2,
            "count": 0
           },
           {
            "bin_end": 0.4,
            "bin_start": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_end": 0.5,
            "bin_start": 0.4,
            "count": 0
           },
           {
            "bin_end": 0.6000000000000001,
            "bin_start": 0.5,
            "count": 0
           },
           {
            "bin_end": 0.7000000000000001,
            "bin_start": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_end": 0.8,
            "bin_start": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_end": 0.9,
            "bin_start": 0.8,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9,
            "count": 0
           }
          ],
          "max": null,
          "min": null,
          "nan_count": 5,
          "unique_count": 0
         }
        },
        {
         "dtype": "int64",
         "name": "target",
         "stats": {
          "histogram": [
           {
            "bin_end": 0.6,
            "bin_start": 0.5,
            "count": 0
           },
           {
            "bin_end": 0.7,
            "bin_start": 0.6,
            "count": 0
           },
           {
            "bin_end": 0.8,
            "bin_start": 0.7,
            "count": 0
           },
           {
            "bin_end": 0.9,
            "bin_start": 0.8,
            "count": 0
           },
           {
            "bin_end": 1,
            "bin_start": 0.9,
            "count": 0
           },
           {
            "bin_end": 1.1,
            "bin_start": 1,
            "count": 5
           },
           {
            "bin_end": 1.2000000000000002,
            "bin_start": 1.1,
            "count": 0
           },
           {
            "bin_end": 1.3,
            "bin_start": 1.2000000000000002,
            "count": 0
           },
           {
            "bin_end": 1.4,
            "bin_start": 1.3,
            "count": 0
           },
           {
            "bin_end": 1.5,
            "bin_start": 1.4,
            "count": 0
           }
          ],
          "max": "1",
          "min": "1",
          "nan_count": 0,
          "unique_count": 1
         }
        },
        {
         "dtype": "int64",
         "name": "word_count",
         "stats": {
          "histogram": [
           {
            "bin_end": 7.3,
            "bin_start": 6,
            "count": 2
           },
           {
            "bin_end": 8.6,
            "bin_start": 7.3,
            "count": 0
           },
           {
            "bin_end": 9.9,
            "bin_start": 8.6,
            "count": 1
           },
           {
            "bin_end": 11.2,
            "bin_start": 9.9,
            "count": 0
           },
           {
            "bin_end": 12.5,
            "bin_start": 11.2,
            "count": 0
           },
           {
            "bin_end": 13.8,
            "bin_start": 12.5,
            "count": 1
           },
           {
            "bin_end": 15.1,
            "bin_start": 13.8,
            "count": 0
           },
           {
            "bin_end": 16.4,
            "bin_start": 15.1,
            "count": 0
           },
           {
            "bin_end": 17.700000000000003,
            "bin_start": 16.4,
            "count": 0
           },
           {
            "bin_end": 19,
            "bin_start": 17.700000000000003,
            "count": 1
           }
          ],
          "max": "19",
          "min": "6",
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "tweet_tokens",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "['Just', 'happened', 'a', 'terrible', 'car', 'crash']"
           },
           {
            "count": 1,
            "name": "['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "tweet_tokens_joined",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened a terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "cleaned_tweets",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "['Just', 'happened', 'terrible', 'car', 'crash']"
           },
           {
            "count": 1,
            "name": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us']"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "cleaned_tweets_joined",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds Reason #earthquake May ALLAH Forgive us"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "lemmatized_tweets",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "['Just', 'happened', 'terrible', 'car', 'crash']"
           },
           {
            "count": 1,
            "name": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'u']"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "object",
         "name": "lemmatized_tweets_joined",
         "stats": {
          "categories": [
           {
            "count": 1,
            "name": "Just happened terrible car crash"
           },
           {
            "count": 1,
            "name": "Our Deeds Reason #earthquake May ALLAH Forgive u"
           },
           {
            "count": 3,
            "name": "3 others"
           }
          ],
          "nan_count": 0,
          "unique_count": 5
         }
        },
        {
         "dtype": "int64",
         "name": "_deepnote_index_column"
        }
       ],
       "row_count": 5,
       "rows": [
        {
         "_deepnote_index_column": 0,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Just', 'happened', 'terrible', 'car', 'crash']",
         "cleaned_tweets_joined": "Just happened terrible car crash",
         "keyword": "nan",
         "lemmatized_tweets": "['Just', 'happened', 'terrible', 'car', 'crash']",
         "lemmatized_tweets_joined": "Just happened terrible car crash",
         "location": "nan",
         "target": 1,
         "text": "Just happened a terrible car crash",
         "tweet_tokens": "['Just', 'happened', 'a', 'terrible', 'car', 'crash']",
         "tweet_tokens_joined": "Just happened a terrible car crash",
         "tweetid": 1,
         "userid": "nan",
         "word_count": 6
        },
        {
         "_deepnote_index_column": 1,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us']",
         "cleaned_tweets_joined": "Our Deeds Reason #earthquake May ALLAH Forgive us",
         "keyword": "nan",
         "lemmatized_tweets": "['Our', 'Deeds', 'Reason', '#earthquake', 'May', 'ALLAH', 'Forgive', 'u']",
         "lemmatized_tweets_joined": "Our Deeds Reason #earthquake May ALLAH Forgive u",
         "location": "nan",
         "target": 1,
         "text": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all",
         "tweet_tokens": "['Our', 'Deeds', 'are', 'the', 'Reason', 'of', 'this', '#earthquake', 'May', 'ALLAH', 'Forgive', 'us', 'all']",
         "tweet_tokens_joined": "Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all",
         "tweetid": 13,
         "userid": "nan",
         "word_count": 13
        },
        {
         "_deepnote_index_column": 2,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Heard', '#earthquake', 'different', 'cities,', 'stay', 'safe', 'everyone.']",
         "cleaned_tweets_joined": "Heard #earthquake different cities, stay safe everyone.",
         "keyword": "nan",
         "lemmatized_tweets": "['Heard', '#earthquake', 'different', 'cities,', 'stay', 'safe', 'everyone.']",
         "lemmatized_tweets_joined": "Heard #earthquake different cities, stay safe everyone.",
         "location": "nan",
         "target": 1,
         "text": "Heard about #earthquake is different cities, stay safe everyone.",
         "tweet_tokens": "['Heard', 'about', '#earthquake', 'is', 'different', 'cities,', 'stay', 'safe', 'everyone.']",
         "tweet_tokens_joined": "Heard about #earthquake is different cities, stay safe everyone.",
         "tweetid": 14,
         "userid": "nan",
         "word_count": 9
        },
        {
         "_deepnote_index_column": 3,
         "choose_one": "Relevant",
         "cleaned_tweets": "['forest', 'fire', 'spot', 'pond,', 'geese', 'fleeing', 'across', 'street,', 'I', 'cannot', 'save']",
         "cleaned_tweets_joined": "forest fire spot pond, geese fleeing across street, I cannot save",
         "keyword": "nan",
         "lemmatized_tweets": "['forest', 'fire', 'spot', 'pond,', 'goose', 'fleeing', 'across', 'street,', 'I', 'cannot', 'save']",
         "lemmatized_tweets_joined": "forest fire spot pond, goose fleeing across street, I cannot save",
         "location": "nan",
         "target": 1,
         "text": "there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all",
         "tweet_tokens": "['there', 'is', 'a', 'forest', 'fire', 'at', 'spot', 'pond,', 'geese', 'are', 'fleeing', 'across', 'the', 'street,', 'I', 'cannot', 'save', 'them', 'all']",
         "tweet_tokens_joined": "there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all",
         "tweetid": 15,
         "userid": "nan",
         "word_count": 19
        },
        {
         "_deepnote_index_column": 4,
         "choose_one": "Relevant",
         "cleaned_tweets": "['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask.', 'Canada']",
         "cleaned_tweets_joined": "Forest fire near La Ronge Sask. Canada",
         "keyword": "nan",
         "lemmatized_tweets": "['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask.', 'Canada']",
         "lemmatized_tweets_joined": "Forest fire near La Ronge Sask. Canada",
         "location": "nan",
         "target": 1,
         "text": "Forest fire near La Ronge Sask. Canada",
         "tweet_tokens": "['Forest', 'fire', 'near', 'La', 'Ronge', 'Sask.', 'Canada']",
         "tweet_tokens_joined": "Forest fire near La Ronge Sask. Canada",
         "tweetid": 16,
         "userid": "nan",
         "word_count": 7
        }
       ]
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choose_one</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>tweet_tokens_joined</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>cleaned_tweets_joined</th>\n",
       "      <th>lemmatized_tweets</th>\n",
       "      <th>lemmatized_tweets_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[Just, happened, a, terrible, car, crash]</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[Just, happened, terrible, car, crash]</td>\n",
       "      <td>Just happened terrible car crash</td>\n",
       "      <td>[Just, happened, terrible, car, crash]</td>\n",
       "      <td>Just happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #eart...</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[Our, Deeds, Reason, #earthquake, May, ALLAH, ...</td>\n",
       "      <td>Our Deeds Reason #earthquake May ALLAH Forgive us</td>\n",
       "      <td>[Our, Deeds, Reason, #earthquake, May, ALLAH, ...</td>\n",
       "      <td>Our Deeds Reason #earthquake May ALLAH Forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[Heard, about, #earthquake, is, different, cit...</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[Heard, #earthquake, different, cities,, stay,...</td>\n",
       "      <td>Heard #earthquake different cities, stay safe ...</td>\n",
       "      <td>[Heard, #earthquake, different, cities,, stay,...</td>\n",
       "      <td>Heard #earthquake different cities, stay safe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>[there, is, a, forest, fire, at, spot, pond,, ...</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[forest, fire, spot, pond,, geese, fleeing, ac...</td>\n",
       "      <td>forest fire spot pond, geese fleeing across st...</td>\n",
       "      <td>[forest, fire, spot, pond,, goose, fleeing, ac...</td>\n",
       "      <td>forest fire spot pond, goose fleeing across st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask., Canada]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask., Canada]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask., Canada]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choose_one keyword location  \\\n",
       "0   Relevant     NaN      NaN   \n",
       "1   Relevant     NaN      NaN   \n",
       "2   Relevant     NaN      NaN   \n",
       "3   Relevant     NaN      NaN   \n",
       "4   Relevant     NaN      NaN   \n",
       "\n",
       "                                                text  tweetid  userid  target  \\\n",
       "0                 Just happened a terrible car crash      1.0     NaN       1   \n",
       "1  Our Deeds are the Reason of this #earthquake M...     13.0     NaN       1   \n",
       "2  Heard about #earthquake is different cities, s...     14.0     NaN       1   \n",
       "3  there is a forest fire at spot pond, geese are...     15.0     NaN       1   \n",
       "4             Forest fire near La Ronge Sask. Canada     16.0     NaN       1   \n",
       "\n",
       "   word_count                                       tweet_tokens  \\\n",
       "0           6          [Just, happened, a, terrible, car, crash]   \n",
       "1          13  [Our, Deeds, are, the, Reason, of, this, #eart...   \n",
       "2           9  [Heard, about, #earthquake, is, different, cit...   \n",
       "3          19  [there, is, a, forest, fire, at, spot, pond,, ...   \n",
       "4           7     [Forest, fire, near, La, Ronge, Sask., Canada]   \n",
       "\n",
       "                                 tweet_tokens_joined  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Our Deeds are the Reason of this #earthquake M...   \n",
       "2  Heard about #earthquake is different cities, s...   \n",
       "3  there is a forest fire at spot pond, geese are...   \n",
       "4             Forest fire near La Ronge Sask. Canada   \n",
       "\n",
       "                                      cleaned_tweets  \\\n",
       "0             [Just, happened, terrible, car, crash]   \n",
       "1  [Our, Deeds, Reason, #earthquake, May, ALLAH, ...   \n",
       "2  [Heard, #earthquake, different, cities,, stay,...   \n",
       "3  [forest, fire, spot, pond,, geese, fleeing, ac...   \n",
       "4     [Forest, fire, near, La, Ronge, Sask., Canada]   \n",
       "\n",
       "                               cleaned_tweets_joined  \\\n",
       "0                   Just happened terrible car crash   \n",
       "1  Our Deeds Reason #earthquake May ALLAH Forgive us   \n",
       "2  Heard #earthquake different cities, stay safe ...   \n",
       "3  forest fire spot pond, geese fleeing across st...   \n",
       "4             Forest fire near La Ronge Sask. Canada   \n",
       "\n",
       "                                   lemmatized_tweets  \\\n",
       "0             [Just, happened, terrible, car, crash]   \n",
       "1  [Our, Deeds, Reason, #earthquake, May, ALLAH, ...   \n",
       "2  [Heard, #earthquake, different, cities,, stay,...   \n",
       "3  [forest, fire, spot, pond,, goose, fleeing, ac...   \n",
       "4     [Forest, fire, near, La, Ronge, Sask., Canada]   \n",
       "\n",
       "                            lemmatized_tweets_joined  \n",
       "0                   Just happened terrible car crash  \n",
       "1   Our Deeds Reason #earthquake May ALLAH Forgive u  \n",
       "2  Heard #earthquake different cities, stay safe ...  \n",
       "3  forest fire spot pond, goose fleeing across st...  \n",
       "4             Forest fire near La Ronge Sask. Canada  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "data['lemmatized_tweets'] = data.apply(lambda row: [wnl.lemmatize(w) for w in row[\"cleaned_tweets\"]], axis = 1)\n",
    "data[\"lemmatized_tweets_joined\"] = data.apply(lambda row: \" \".join(row[\"lemmatized_tweets\"]), axis = 1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6cc5b975-c378-4446-8b15-03c3047279ca' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "0f965c63-46de-49b5-8d66-16e9b7abfc2f",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
